---
title: "Goal: build a Streamlit app to show how spaCy works on ANSP texts"
description: |
  Can I get it done this week? 
author:
  - name: Amanda Whitmire
    url: https://amandawhitmire.github.io/
    affiliation: Stanford Libraries & Hopkins Marine Station
date: 09-20-2021
collections:
  posts:
    disqus: ansp-streamlit-concept
    share: [twitter, facebook]
output:
  distill::distill_article:
    self_contained: false
    
draft: false
preview: https://raw.githubusercontent.com/amandawhitmire/blog/main/images/ansp-taxa-streamlit-concept.jpeg
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Workspace setup

Load the Libraries we need.

```{r libraries, echo=TRUE, message=FALSE}
library(rmarkdown)
library(knitr)
library(distill)
```

## Introduction

It's Monday morning and I've got my coffee - time to get going for the week! This will be a quick post to share my project for the week - getting a [Streamlit](https://streamlit.io/) app up and running. More specifically, I'd like to spin up `spaCy` in an app with pre-loaded volumes (or articles?) from the Proceedings of the Academy of Natural Sciences of Philadelphia (ANSP). There is a [demo version](https://share.streamlit.io/ines/spacy-streamlit-demo/app.py) of this kind of Streamlit app that I can (and will) fork. I've already been wading around in the back-end of Streamlit, and it's safe to say that while forking and adapting the demo app sounds simple, it's at the edges of my Python comfort level (which is very basic). This is likely to be a slow process laden with muttered cuss words, but it will still be great fun. Here's the plan:
 
```{r, layout="l-body-outset"}
include_graphics("https://raw.githubusercontent.com/amandawhitmire/blog/main/images/ansp-taxa-streamlit-concept.jpeg")
```

The general layout of the demo app is _very close_ to what we want, which is FANTASTIC luck. You can see that we will have options to load texts (upload, copy/paste, or use provided set), the app will perform the `spaCy` natural language processing (NLP) pipeline, and visualize certain components. The named entity recognition (NER) results are shown as highlighted words. The [default entities](https://spacy.io/api/annotation#named-entities) include things like people, geopolitical entities (countries, cities, states), dates, times, and so on. I'll be adding two custom entity types in our app: taxonomic names that I've already identified in the corpus (see [last post](https://amandawhitmire.github.io/blog/posts/2021-09-16-scrape-all-taxa/)), and a set of habitats identified^[from: Nguyen N, Gabud R, Ananiadou S (2019) COPIOUS: A gold standard corpus of named entities towards extracting species occurrence from biodiversity literature. Biodiversity Data Journal 7: e29626. https://doi.org/10.3897/BDJ.7.e29626] in texts from the [Biodiversty Heritage Library](https://www.biodiversitylibrary.org/). 

Below the NER results, we can show the tokens^["Tokenization is the task of splitting a text into meaningful segments, called tokens." [spaCy](https://spacy.io/usage/linguistic-features#tokenization)] from the NLP process. This is helpful and interesting because the current goal of my project is to identify species occurrences ("I saw this thing, at this place, on this day.") in the corpus. To accomplish this, we have to get far beyond just finding genus and species names in the text - we need to train `spaCy` to find sentences that are good candidates for having taxa + location + date info. This is way harder! Understanding how `spaCy` "sees" the Proceedings will help us understand how the model is functioning. 

```{r, layout="l-body-outset"}
include_graphics("https://raw.githubusercontent.com/amandawhitmire/blog/main/images/spacy-streamlit-token-table.jpg")
```

So, that's what I'll be up to this week ... 
